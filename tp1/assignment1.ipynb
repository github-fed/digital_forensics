{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lpips\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of image files in the folder\n",
    "image_files = [\"256x256.png\", \"512x512.png\", \"1000x1000.png\", \"2000x2000.png\"]\n",
    "\n",
    "# Loop over each image and convert to grayscale\n",
    "for image_file in image_files:\n",
    "    # Open the image\n",
    "    img = Image.open(os.path.join('assets', image_file))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_img = img.convert(\"L\")  # 'L' mode stands for grayscale\n",
    "\n",
    "    # Save the grayscale image to the output folder\n",
    "    grayscale_img.save(os.path.join('assets', f\"grayscale_{image_file}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscaled_images = [\"grayscale_256x256.png\", \"grayscale_512x512.png\", \"grayscale_1000x1000.png\", \"grayscale_2000x2000.png\"]\n",
    "for image_file in grayscaled_images:\n",
    "    # Open the PNG image\n",
    "    img = Image.open(f\"assets/{image_file}\")\n",
    "\n",
    "    # Convert to JPEG format and save with compression\n",
    "    img = img.convert(\"RGB\")\n",
    "    img.save(f\"assets/{image_file}_compressed_q85.jpg\", \"JPEG\", quality=85)  # 'quality' ranges from 1 (worst) to 95 (best)\n",
    "    img.save(f\"assets/{image_file}_compressed_q5.jpg\", \"JPEG\", quality=5)  # 'quality' ranges from 1 (worst) to 95 (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in grayscaled_images:\n",
    "    # Open the PNG image\n",
    "    img = Image.open(f\"assets/{image_file}\")\n",
    "    img = img.convert(\"RGB\")  # Convert to RGB format if necessary\n",
    "\n",
    "    # Convert image to numpy array\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    for stddev in [25, 85]:\n",
    "        # Define Gaussian noise parameters\n",
    "        mean = 0\n",
    "\n",
    "        # Generate Gaussian noise\n",
    "        gaussian_noise = np.random.normal(mean, stddev, img_array.shape)\n",
    "\n",
    "        # Add the Gaussian noise to the image\n",
    "        noisy_img_array = img_array + gaussian_noise\n",
    "\n",
    "        # Ensure pixel values are within [0, 255] range\n",
    "        noisy_img_array = np.clip(noisy_img_array, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Convert back to a PIL image\n",
    "        noisy_img = Image.fromarray(noisy_img_array)\n",
    "\n",
    "        # Save the noisy image\n",
    "        noisy_img.save(f\"assets/gaussian{stddev}_{image_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for JPEG compressed q85 image: 21.508682250976562\n",
      "MSE for JPEG compressed q5 image: 239.91409301757812\n",
      "MSE for image with Gaussian noise 85: 2205.6570587158203\n",
      "MSE for image with Gaussian noise 25: 262.55091857910156\n",
      "\n",
      "MSE for JPEG compressed q85 image: 18.49268341064453\n",
      "MSE for JPEG compressed q5 image: 293.5249938964844\n",
      "MSE for image with Gaussian noise 85: 2229.9584617614746\n",
      "MSE for image with Gaussian noise 25: 263.73778915405273\n",
      "\n",
      "MSE for JPEG compressed q85 image: 2.642072\n",
      "MSE for JPEG compressed q5 image: 74.442835\n",
      "MSE for image with Gaussian noise 85: 2269.365355\n",
      "MSE for image with Gaussian noise 25: 268.080716\n",
      "\n",
      "MSE for JPEG compressed q85 image: 1.05619\n",
      "MSE for JPEG compressed q5 image: 66.402881\n",
      "MSE for image with Gaussian noise 85: 2133.43445675\n",
      "MSE for image with Gaussian noise 25: 184.2664925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    }
   ],
   "source": [
    "# Function to compute MSE between two images\n",
    "def mse(imageA, imageB):\n",
    "    # Compute the mean squared error\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    \n",
    "    return err\n",
    "\n",
    "# Load images (grayscale images)\n",
    "for image_file in grayscaled_images:\n",
    "    original = cv2.imread(f\"assets/{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q85 = cv2.imread(f\"assets/{image_file}_compressed_q85.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q5 = cv2.imread(f\"assets/{image_file}_compressed_q5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_85 = cv2.imread(f\"assets/gaussian85_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_25 = cv2.imread(f\"assets/gaussian25_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Calculate MSE between the original and distorted images\n",
    "    mse_jpeg_85 = mse(original, jpeg_compressed_q85)\n",
    "    mse_jpeg_5 = mse(original, jpeg_compressed_q5)\n",
    "    mse_noise_85 = mse(original, gaussian_noise_85)\n",
    "    mse_noise_25 = mse(original, gaussian_noise_25)\n",
    "\n",
    "    print(f\"MSE for JPEG compressed q85 image: {mse_jpeg_85}\")\n",
    "    print(f\"MSE for JPEG compressed q5 image: {mse_jpeg_5}\")\n",
    "    print(f\"MSE for image with Gaussian noise 85: {mse_noise_85}\")\n",
    "    print(f\"MSE for image with Gaussian noise 25: {mse_noise_25}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR for JPEG compressed q85 image: 34.80466557112713 dB\n",
      "PSNR for JPEG compressed q5 image: 34.80466557112713 dB\n",
      "PSNR for image with Gaussian noise 85: 14.695423727480229 dB\n",
      "PSNR for image with Gaussian noise 25: 23.938668187889704 dB\n",
      "\n",
      "PSNR for JPEG compressed q85 image: 35.46080426134991 dB\n",
      "PSNR for JPEG compressed q5 image: 35.46080426134991 dB\n",
      "PSNR for image with Gaussian noise 85: 14.647835875039629 dB\n",
      "PSNR for image with Gaussian noise 25: 23.919079995793254 dB\n",
      "\n",
      "PSNR for JPEG compressed q85 image: 43.91135712321942 dB\n",
      "PSNR for JPEG compressed q5 image: 43.91135712321942 dB\n",
      "PSNR for image with Gaussian noise 85: 14.571759403963151 dB\n",
      "PSNR for image with Gaussian noise 25: 23.848147861092052 dB\n",
      "\n",
      "PSNR for JPEG compressed q85 image: 47.893383095932776 dB\n",
      "PSNR for JPEG compressed q5 image: 47.893383095932776 dB\n",
      "PSNR for image with Gaussian noise 85: 14.840010558375889 dB\n",
      "PSNR for image with Gaussian noise 25: 25.476339917116153 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    }
   ],
   "source": [
    "# Function to compute PSNR\n",
    "def psnr(imageA, imageB):\n",
    "    mse_value = mse(imageA, imageB)\n",
    "    if mse_value == 0:\n",
    "        return float('inf')  # PSNR is infinite if MSE is zero (identical images)\n",
    "    max_pixel_value = 255.0\n",
    "    return 10 * np.log10((max_pixel_value ** 2) / mse_value)\n",
    "\n",
    "for image_file in grayscaled_images:\n",
    "    original = cv2.imread(f\"assets/{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q85 = cv2.imread(f\"assets/{image_file}_compressed_q85.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q5 = cv2.imread(f\"assets/{image_file}_compressed_q5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_85 = cv2.imread(f\"assets/gaussian85_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_25 = cv2.imread(f\"assets/gaussian25_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    psnr_jpeg_85 = psnr(original, jpeg_compressed_q85)\n",
    "    psnr_jpeg_5 = psnr(original, jpeg_compressed_q5)\n",
    "    psnr_noise_85 = psnr(original, gaussian_noise_85)\n",
    "    psnr_noise_25 = psnr(original, gaussian_noise_25)\n",
    "\n",
    "    print(f\"PSNR for JPEG compressed q85 image: {psnr_jpeg_85} dB\")\n",
    "    print(f\"PSNR for JPEG compressed q5 image: {psnr_jpeg_85} dB\")\n",
    "    print(f\"PSNR for image with Gaussian noise 85: {psnr_noise_85} dB\")\n",
    "    print(f\"PSNR for image with Gaussian noise 25: {psnr_noise_25} dB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM for JPEG compressed q85 image: 0.9416431808231807\n",
      "SSIM for JPEG compressed q5 image: 0.5362863452715882\n",
      "SSIM for image with Gaussian noise 85: 0.1692192179584619\n",
      "SSIM for image with Gaussian noise 25: 0.5647442555127854\n",
      "\n",
      "SSIM for JPEG compressed q85 image: 0.9618688799688425\n",
      "SSIM for JPEG compressed q5 image: 0.5797062614359662\n",
      "SSIM for image with Gaussian noise 85: 0.20268074488668306\n",
      "SSIM for image with Gaussian noise 25: 0.6142521132218415\n",
      "\n",
      "SSIM for JPEG compressed q85 image: 0.9872683859722619\n",
      "SSIM for JPEG compressed q5 image: 0.8379614795159436\n",
      "SSIM for image with Gaussian noise 85: 0.06173434515785253\n",
      "SSIM for image with Gaussian noise 25: 0.27799044993851924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM for JPEG compressed q85 image: 0.9939585222470035\n",
      "SSIM for JPEG compressed q5 image: 0.35898882122947356\n",
      "SSIM for image with Gaussian noise 85: 0.027127364587235626\n",
      "SSIM for image with Gaussian noise 25: 0.1579069814721672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image_file in grayscaled_images:\n",
    "    original = cv2.imread(f\"assets/{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q85 = cv2.imread(f\"assets/{image_file}_compressed_q85.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q5 = cv2.imread(f\"assets/{image_file}_compressed_q5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_85 = cv2.imread(f\"assets/gaussian85_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_25 = cv2.imread(f\"assets/gaussian25_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ssim_jpeg_85 = ssim(original, jpeg_compressed_q85)\n",
    "    ssim_jpeg_5 = ssim(original, jpeg_compressed_q5)\n",
    "    ssim_noise_85 = ssim(original, gaussian_noise_85)\n",
    "    ssim_noise_25 = ssim(original, gaussian_noise_25)\n",
    "\n",
    "    print(f\"SSIM for JPEG compressed q85 image: {ssim_jpeg_85}\")\n",
    "    print(f\"SSIM for JPEG compressed q5 image: {ssim_jpeg_5}\")\n",
    "    print(f\"SSIM for image with Gaussian noise 85: {ssim_noise_85}\")\n",
    "    print(f\"SSIM for image with Gaussian noise 25: {ssim_noise_25}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPIPS for JPEG compressed 85 image: 0.06532569229602814\n",
      "LPIPS for JPEG compressed 5 image: 0.6539527773857117\n",
      "LPIPS for image with Gaussian noise 85: 0.5873231291770935\n",
      "LPIPS for image with Gaussian noise 25: 0.5873231291770935\n",
      "\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "LPIPS for JPEG compressed 85 image: 0.054089441895484924\n",
      "LPIPS for JPEG compressed 5 image: 0.5784404873847961\n",
      "LPIPS for image with Gaussian noise 85: 0.6334884166717529\n",
      "LPIPS for image with Gaussian noise 25: 0.6334884166717529\n",
      "\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "LPIPS for JPEG compressed 85 image: 0.03976515308022499\n",
      "LPIPS for JPEG compressed 5 image: 0.3610612750053406\n",
      "LPIPS for image with Gaussian noise 85: 0.7631084322929382\n",
      "LPIPS for image with Gaussian noise 25: 0.7631084322929382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /Users/denisfedosov/Library/Caches/pypoetry/virtualenvs/df-p3ghjSHb-py3.12/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "LPIPS for JPEG compressed 85 image: 0.012160254642367363\n",
      "LPIPS for JPEG compressed 5 image: 0.130621999502182\n",
      "LPIPS for image with Gaussian noise 85: 0.7949854731559753\n",
      "LPIPS for image with Gaussian noise 25: 0.7949854731559753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image_file in grayscaled_images:\n",
    "    original = cv2.imread(f\"assets/{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q85 = cv2.imread(f\"assets/{image_file}_compressed_q85.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    jpeg_compressed_q5 = cv2.imread(f\"assets/{image_file}_compressed_q5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_85 = cv2.imread(f\"assets/gaussian85_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "    gaussian_noise_25 = cv2.imread(f\"assets/gaussian25_{image_file}\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Convert grayscale to RGB by repeating the channel and normalize\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_GRAY2RGB) / 255.0\n",
    "    jpeg_compressed_85_rgb = cv2.cvtColor(jpeg_compressed_q85, cv2.COLOR_GRAY2RGB) / 255.0\n",
    "    jpeg_compressed_5_rgb = cv2.cvtColor(jpeg_compressed_q5, cv2.COLOR_GRAY2RGB) / 255.0\n",
    "    gaussian_noise_85_rgb = cv2.cvtColor(gaussian_noise_85, cv2.COLOR_GRAY2RGB) / 255.0\n",
    "    gaussian_noise_25_rgb = cv2.cvtColor(gaussian_noise_85, cv2.COLOR_GRAY2RGB) / 255.0\n",
    "\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    original_tensor = torch.from_numpy(original_rgb).permute(2, 0, 1).float()  # Shape: (C, H, W)\n",
    "    jpeg_compressed_85_tensor = torch.from_numpy(jpeg_compressed_85_rgb).permute(2, 0, 1).float()\n",
    "    jpeg_compressed_5_tensor = torch.from_numpy(jpeg_compressed_5_rgb).permute(2, 0, 1).float()\n",
    "    gaussian_noise_85_tensor = torch.from_numpy(gaussian_noise_85_rgb).permute(2, 0, 1).float()\n",
    "    gaussian_noise_25_tensor = torch.from_numpy(gaussian_noise_25_rgb).permute(2, 0, 1).float()\n",
    "\n",
    "    lpips_model = lpips.LPIPS(net='vgg')\n",
    "\n",
    "    # Calculate LPIPS\n",
    "    lpips_jpeg_85 = lpips_model(original_tensor.unsqueeze(0), jpeg_compressed_85_tensor.unsqueeze(0)).item()  # Add batch dimension\n",
    "    lpips_jpeg_5 = lpips_model(original_tensor.unsqueeze(0), jpeg_compressed_5_tensor.unsqueeze(0)).item()\n",
    "    lpips_noise_85 = lpips_model(original_tensor.unsqueeze(0), gaussian_noise_85_tensor.unsqueeze(0)).item()\n",
    "    lpips_noise_25 = lpips_model(original_tensor.unsqueeze(0), gaussian_noise_25_tensor.unsqueeze(0)).item()\n",
    "\n",
    "    print(f\"LPIPS for JPEG compressed 85 image: {lpips_jpeg_85}\")\n",
    "    print(f\"LPIPS for JPEG compressed 5 image: {lpips_jpeg_5}\")\n",
    "    print(f\"LPIPS for image with Gaussian noise 85: {lpips_noise_85}\")\n",
    "    print(f\"LPIPS for image with Gaussian noise 25: {lpips_noise_25}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df-p3ghjSHb-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
